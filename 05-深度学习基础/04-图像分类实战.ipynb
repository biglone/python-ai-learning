{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4课：图像分类实战\n",
    "\n",
    "## 学习目标\n",
    "- 掌握图像数据预处理\n",
    "- 学会使用预训练模型\n",
    "- 理解迁移学习\n",
    "- 完成 CIFAR-10 分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据加载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 类别\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 数据增强\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化数据增强效果\n",
    "def show_augmentation(dataset, idx=0):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    \n",
    "    # 原始图像\n",
    "    original_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    original_dataset = datasets.CIFAR10('./data', train=True, transform=original_transform)\n",
    "    original_img, label = original_dataset[idx]\n",
    "    \n",
    "    axes[0, 0].imshow(original_img.permute(1, 2, 0))\n",
    "    axes[0, 0].set_title(f'原始: {classes[label]}')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # 增强后的图像\n",
    "    for i in range(1, 10):\n",
    "        ax = axes[i // 5, i % 5]\n",
    "        img, _ = dataset[idx]\n",
    "        # 反归一化显示\n",
    "        img = img * torch.tensor([0.2470, 0.2435, 0.2616]).view(3, 1, 1)\n",
    "        img = img + torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        ax.imshow(img.permute(1, 2, 0))\n",
    "        ax.set_title(f'增强 {i}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_augmentation(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 构建自定义 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "        \n",
    "        # 卷积块 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)  # 32 -> 16\n",
    "        )\n",
    "        \n",
    "        # 卷积块 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)  # 16 -> 8\n",
    "        )\n",
    "        \n",
    "        # 卷积块 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)  # 8 -> 4\n",
    "        )\n",
    "        \n",
    "        # 分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = CIFAR10CNN().to(device)\n",
    "print(f\"参数量: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练设置\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * data.size(0)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += target.size(0)\n",
    "    \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += criterion(output, target).item() * data.size(0)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "    \n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "num_epochs = 10\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    print(f'  LR: {scheduler.get_last_lr()[0]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练历史\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='训练')\n",
    "axes[0].plot(history['test_loss'], label='测试')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('损失曲线')\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='训练')\n",
    "axes[1].plot(history['test_acc'], label='测试')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('准确率曲线')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用预训练的 ResNet\n",
    "def create_resnet_model(num_classes=10, pretrained=True):\n",
    "    # 加载预训练模型\n",
    "    model = models.resnet18(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "    \n",
    "    # 修改第一层（因为 CIFAR-10 是 32x32）\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()  # 移除 maxpool\n",
    "    \n",
    "    # 修改最后一层\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "resnet_model = create_resnet_model().to(device)\n",
    "print(f\"ResNet18 参数量: {sum(p.numel() for p in resnet_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冻结部分层进行微调\n",
    "def freeze_layers(model, num_layers_to_freeze):\n",
    "    \"\"\"冻结前 N 层\"\"\"\n",
    "    layers = list(model.children())\n",
    "    for i, layer in enumerate(layers[:num_layers_to_freeze]):\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"可训练参数: {trainable:,} / {total:,}\")\n",
    "\n",
    "# 冻结前 6 层\n",
    "freeze_layers(resnet_model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练迁移学习模型\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, resnet_model.parameters()), \n",
    "                        lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# 训练几个 epoch\n",
    "for epoch in range(5):\n",
    "    train_loss, train_acc = train_one_epoch(resnet_model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(resnet_model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/5')\n",
    "    print(f'  Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型评估与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def get_predictions(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            preds = output.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(target.numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "preds, labels = get_predictions(model, test_loader, device)\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('预测类别')\n",
    "plt.ylabel('真实类别')\n",
    "plt.title('混淆矩阵')\n",
    "plt.show()\n",
    "\n",
    "# 分类报告\n",
    "print(\"分类报告:\")\n",
    "print(classification_report(labels, preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化错误预测\n",
    "def show_misclassified(model, test_loader, device, num_images=10):\n",
    "    model.eval()\n",
    "    misclassified = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            preds = output.argmax(dim=1)\n",
    "            \n",
    "            wrong_idx = (preds != target).nonzero().squeeze()\n",
    "            if wrong_idx.dim() == 0:\n",
    "                wrong_idx = wrong_idx.unsqueeze(0)\n",
    "            \n",
    "            for idx in wrong_idx:\n",
    "                if len(misclassified) >= num_images:\n",
    "                    break\n",
    "                misclassified.append({\n",
    "                    'image': data[idx].cpu(),\n",
    "                    'true': target[idx].item(),\n",
    "                    'pred': preds[idx].item()\n",
    "                })\n",
    "            \n",
    "            if len(misclassified) >= num_images:\n",
    "                break\n",
    "    \n",
    "    # 显示\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(misclassified):\n",
    "            img = misclassified[i]['image']\n",
    "            # 反归一化\n",
    "            img = img * torch.tensor([0.2470, 0.2435, 0.2616]).view(3, 1, 1)\n",
    "            img = img + torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            \n",
    "            ax.imshow(img.permute(1, 2, 0))\n",
    "            ax.set_title(f'真实: {classes[misclassified[i][\"true\"]]}\\n预测: {classes[misclassified[i][\"pred\"]]}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_misclassified(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 保存和加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': num_epochs,\n",
    "    'history': history\n",
    "}, 'cifar10_model.pth')\n",
    "\n",
    "print(\"模型已保存\")\n",
    "\n",
    "# 加载模型\n",
    "checkpoint = torch.load('cifar10_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(\"模型已加载\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 练习题\n",
    "\n",
    "### 练习：尝试不同的模型架构和超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里编写代码\n",
    "# 1. 尝试使用其他预训练模型（如 VGG、DenseNet）\n",
    "# 2. 调整数据增强策略\n",
    "# 3. 尝试不同的优化器和学习率调度\n",
    "# 4. 比较不同配置的性能\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 本课小结\n",
    "\n",
    "1. **数据增强**：RandomFlip、RandomCrop、ColorJitter\n",
    "2. **模型设计**：卷积块、BatchNorm、Dropout\n",
    "3. **迁移学习**：使用预训练模型、冻结层\n",
    "4. **训练技巧**：学习率调度、权重衰减\n",
    "5. **评估分析**：混淆矩阵、错误样本分析"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
