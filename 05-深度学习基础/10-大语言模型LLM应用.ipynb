{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10课：大语言模型 (LLM) 应用\n",
    "\n",
    "## 学习目标\n",
    "- 理解大语言模型的基本概念\n",
    "- 学习 Prompt Engineering 技巧\n",
    "- 掌握 LLM API 的使用\n",
    "- 了解 RAG 和 Agent 的基本概念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 大语言模型概述\n",
    "\n",
    "### 什么是大语言模型 (LLM)？\n",
    "\n",
    "大语言模型是基于 Transformer 架构的超大规模神经网络，能够理解和生成自然语言。\n",
    "\n",
    "### 代表性模型\n",
    "\n",
    "| 模型 | 公司 | 参数量 | 特点 |\n",
    "|------|------|--------|------|\n",
    "| GPT-4 | OpenAI | 未公开 | 多模态，强大推理 |\n",
    "| Claude | Anthropic | 未公开 | 长上下文，安全 |\n",
    "| Gemini | Google | 未公开 | 多模态 |\n",
    "| Llama 3 | Meta | 8B-405B | 开源 |\n",
    "| Qwen | 阿里 | 0.5B-72B | 开源，中文优化 |\n",
    "\n",
    "### LLM 的能力\n",
    "\n",
    "1. **文本生成**：写文章、代码、邮件\n",
    "2. **问答对话**：回答问题、聊天\n",
    "3. **文本分析**：情感分析、摘要、翻译\n",
    "4. **推理**：逻辑推理、数学问题\n",
    "5. **代码理解**：代码生成、调试、解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prompt Engineering\n",
    "\n",
    "Prompt Engineering 是设计有效提示词的技术，让 LLM 更好地完成任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 模板示例\n",
    "\n",
    "# 1. 基础提示\n",
    "basic_prompt = \"翻译以下文本到英文：今天天气很好。\"\n",
    "\n",
    "# 2. 角色设定\n",
    "role_prompt = \"\"\"你是一位专业的翻译专家，精通中英文翻译。\n",
    "请将以下中文翻译成地道的英文：\n",
    "今天天气很好，适合出门散步。\"\"\"\n",
    "\n",
    "# 3. Few-shot 示例\n",
    "fewshot_prompt = \"\"\"请根据示例进行情感分类：\n",
    "\n",
    "示例1：\n",
    "输入：这部电影太精彩了！\n",
    "输出：正面\n",
    "\n",
    "示例2：\n",
    "输入：服务态度很差，再也不来了。\n",
    "输出：负面\n",
    "\n",
    "示例3：\n",
    "输入：东西还行，没什么特别的。\n",
    "输出：中性\n",
    "\n",
    "现在请分类：\n",
    "输入：产品质量不错，但物流太慢了。\n",
    "输出：\"\"\"\n",
    "\n",
    "# 4. Chain of Thought (思维链)\n",
    "cot_prompt = \"\"\"请一步步思考并解答以下问题：\n",
    "\n",
    "问题：小明有 5 个苹果，他给了小红 2 个，又买了 3 个，最后又吃了 1 个。请问小明现在有多少个苹果？\n",
    "\n",
    "思考过程：\"\"\"\n",
    "\n",
    "print(\"各种 Prompt 模板已准备好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering 技巧\n",
    "\n",
    "1. **明确角色**：告诉 LLM 扮演什么角色\n",
    "2. **提供上下文**：给出背景信息\n",
    "3. **明确任务**：清楚说明要做什么\n",
    "4. **指定格式**：说明输出格式要求\n",
    "5. **给出示例**：Few-shot learning\n",
    "6. **思维链**：要求逐步推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结构化 Prompt 模板\n",
    "def create_structured_prompt(role, context, task, format_spec, examples=None):\n",
    "    \"\"\"创建结构化的 Prompt\"\"\"\n",
    "    prompt = f\"\"\"# 角色\n",
    "{role}\n",
    "\n",
    "# 背景\n",
    "{context}\n",
    "\n",
    "# 任务\n",
    "{task}\n",
    "\n",
    "# 输出格式\n",
    "{format_spec}\n",
    "\"\"\"\n",
    "    \n",
    "    if examples:\n",
    "        prompt += \"\\n# 示例\\n\"\n",
    "        for i, example in enumerate(examples, 1):\n",
    "            prompt += f\"\\n示例 {i}:\\n{example}\\n\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# 示例：代码审查 Prompt\n",
    "code_review_prompt = create_structured_prompt(\n",
    "    role=\"你是一位经验丰富的 Python 代码审查专家。\",\n",
    "    context=\"用户将提供一段 Python 代码，需要你进行代码审查。\",\n",
    "    task=\"请审查代码，找出潜在问题，并提供改进建议。\",\n",
    "    format_spec=\"\"\"请按以下格式输出：\n",
    "1. 代码概述\n",
    "2. 发现的问题（列表）\n",
    "3. 改进建议（列表）\n",
    "4. 修改后的代码\"\"\",\n",
    "    examples=[\"输入代码: def add(a,b): return a+b\\n输出: 代码简洁，建议添加类型注解...\"]\n",
    ")\n",
    "\n",
    "print(code_review_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用 OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# OpenAI API 使用\n# 安装: pip install openai\n\ntry:\n    from openai import OpenAI\n    OPENAI_AVAILABLE = True\n    print(\"OpenAI 库已安装\")\nexcept ImportError:\n    OPENAI_AVAILABLE = False\n    print(\"请先安装: pip install openai\")\n\ndef call_openai(prompt, model=None, system_prompt=None):\n    \"\"\"\n    调用 OpenAI API\n    需要设置环境变量 OPENAI_API_KEY\n    \n    参数:\n        prompt: 用户提示\n        model: 模型名称，如 \"gpt-4o\", \"gpt-4o-mini\" 等，默认使用 API 默认模型\n        system_prompt: 系统提示（可选）\n    \"\"\"\n    if not OPENAI_AVAILABLE:\n        return \"错误: OpenAI 库未安装\"\n    \n    client = OpenAI()\n    \n    messages = []\n    if system_prompt:\n        messages.append({\"role\": \"system\", \"content\": system_prompt})\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    \n    kwargs = {\n        \"messages\": messages,\n        \"temperature\": 0.7,\n        \"max_tokens\": 1000\n    }\n    \n    if model:\n        kwargs[\"model\"] = model\n    \n    response = client.chat.completions.create(**kwargs)\n    \n    return response.choices[0].message.content\n\n# 使用示例（需要设置 API Key）\n# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n# response = call_openai(\"你好，请介绍一下自己\", model=\"gpt-4o-mini\")\n# print(response)\n\nif OPENAI_AVAILABLE:\n    print(\"\\nOpenAI API 调用函数已准备好\")\n    print(\"使用前请设置 OPENAI_API_KEY 环境变量\")\n    print(\"可用模型: gpt-4o, gpt-4o-mini 等（请参考 OpenAI 官方文档）\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 使用 Anthropic Claude API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Anthropic Claude API 使用\n# 安装: pip install anthropic\n\ntry:\n    import anthropic\n    ANTHROPIC_AVAILABLE = True\n    print(\"Anthropic 库已安装\")\nexcept ImportError:\n    ANTHROPIC_AVAILABLE = False\n    print(\"请先安装: pip install anthropic\")\n\ndef call_claude(prompt, model=None, system_prompt=None):\n    \"\"\"\n    调用 Anthropic Claude API\n    需要设置环境变量 ANTHROPIC_API_KEY\n    \n    参数:\n        prompt: 用户提示\n        model: 模型名称，如 \"claude-sonnet-4-20250514\" 等，默认使用 API 默认模型\n        system_prompt: 系统提示（可选）\n    \"\"\"\n    if not ANTHROPIC_AVAILABLE:\n        return \"错误: Anthropic 库未安装\"\n    \n    client = anthropic.Anthropic()\n    \n    kwargs = {\n        \"max_tokens\": 1024,\n        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n    }\n    \n    if model:\n        kwargs[\"model\"] = model\n    \n    if system_prompt:\n        kwargs[\"system\"] = system_prompt\n    \n    response = client.messages.create(**kwargs)\n    \n    return response.content[0].text\n\n# 使用示例（需要设置 API Key）\n# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"\n# response = call_claude(\"请用 Python 写一个快速排序算法\")\n# print(response)\n\nif ANTHROPIC_AVAILABLE:\n    print(\"\\nClaude API 调用函数已准备好\")\n    print(\"使用前请设置 ANTHROPIC_API_KEY 环境变量\")\n    print(\"可用模型: claude-sonnet-4-20250514 等（请参考 Anthropic 官方文档）\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 使用本地开源模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Hugging Face transformers\n",
    "# 安装: pip install transformers torch\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "    import torch\n",
    "    print(\"Transformers 已安装\")\n",
    "except ImportError:\n",
    "    print(\"请先安装: pip install transformers torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用小模型示例 (GPT-2)\n",
    "def load_local_model(model_name=\"gpt2\"):\n",
    "    \"\"\"加载本地模型\"\"\"\n",
    "    print(f\"正在加载模型: {model_name}\")\n",
    "    generator = pipeline('text-generation', model=model_name)\n",
    "    return generator\n",
    "\n",
    "def generate_text(generator, prompt, max_length=100):\n",
    "    \"\"\"生成文本\"\"\"\n",
    "    result = generator(\n",
    "        prompt, \n",
    "        max_length=max_length, \n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# 使用示例\n",
    "# generator = load_local_model(\"gpt2\")\n",
    "# text = generate_text(generator, \"Once upon a time\")\n",
    "# print(text)\n",
    "\n",
    "print(\"本地模型加载函数已准备好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Ollama 运行本地模型\n",
    "# 安装 Ollama: https://ollama.ai\n",
    "# 然后运行: ollama pull llama3.2\n",
    "\n",
    "import requests\n",
    "\n",
    "def call_ollama(prompt, model=\"llama3.2\"):\n",
    "    \"\"\"调用本地 Ollama 模型\"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        return response.json()[\"response\"]\n",
    "    except Exception as e:\n",
    "        return f\"错误: {e}\\n请确保 Ollama 正在运行\"\n",
    "\n",
    "# 使用示例\n",
    "# response = call_ollama(\"什么是机器学习？\")\n",
    "# print(response)\n",
    "\n",
    "print(\"Ollama 调用函数已准备好\")\n",
    "print(\"使用前请确保 Ollama 正在运行\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RAG (检索增强生成)\n",
    "\n",
    "RAG 是一种增强 LLM 能力的技术，通过检索相关文档来提供更准确的回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单的 RAG 示例\n",
    "class SimpleRAG:\n",
    "    \"\"\"简单的 RAG 实现\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "    \n",
    "    def add_document(self, doc):\n",
    "        \"\"\"添加文档\"\"\"\n",
    "        self.documents.append(doc)\n",
    "    \n",
    "    def search(self, query, top_k=3):\n",
    "        \"\"\"简单的关键词搜索\"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        scores = []\n",
    "        \n",
    "        for doc in self.documents:\n",
    "            doc_words = set(doc.lower().split())\n",
    "            score = len(query_words & doc_words)\n",
    "            scores.append((score, doc))\n",
    "        \n",
    "        scores.sort(reverse=True, key=lambda x: x[0])\n",
    "        return [doc for score, doc in scores[:top_k] if score > 0]\n",
    "    \n",
    "    def generate_prompt(self, query, context_docs):\n",
    "        \"\"\"生成带上下文的 Prompt\"\"\"\n",
    "        context = \"\\n\\n\".join(context_docs)\n",
    "        \n",
    "        prompt = f\"\"\"请根据以下参考资料回答问题。如果资料中没有相关信息，请说明。\n",
    "\n",
    "参考资料：\n",
    "{context}\n",
    "\n",
    "问题：{query}\n",
    "\n",
    "回答：\"\"\"\n",
    "        return prompt\n",
    "\n",
    "# 使用示例\n",
    "rag = SimpleRAG()\n",
    "\n",
    "# 添加一些文档\n",
    "rag.add_document(\"Python 是一种高级编程语言，由 Guido van Rossum 于 1991 年创建。\")\n",
    "rag.add_document(\"机器学习是人工智能的一个分支，让计算机从数据中学习。\")\n",
    "rag.add_document(\"深度学习使用多层神经网络来处理复杂的模式识别任务。\")\n",
    "rag.add_document(\"PyTorch 是 Facebook 开发的深度学习框架，广泛用于研究和生产。\")\n",
    "\n",
    "# 搜索相关文档\n",
    "query = \"什么是深度学习？\"\n",
    "relevant_docs = rag.search(query)\n",
    "\n",
    "print(\"查询:\", query)\n",
    "print(\"\\n相关文档:\")\n",
    "for doc in relevant_docs:\n",
    "    print(f\"- {doc}\")\n",
    "\n",
    "print(\"\\n生成的 Prompt:\")\n",
    "print(rag.generate_prompt(query, relevant_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 向量数据库和语义搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 sentence-transformers 进行语义搜索\n",
    "# 安装: pip install sentence-transformers\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"sentence-transformers 已安装\")\n",
    "except ImportError:\n",
    "    print(\"请先安装: pip install sentence-transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "class SemanticRAG:\n",
    "    \"\"\"基于语义搜索的 RAG\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.documents = []\n",
    "        self.embeddings = None\n",
    "    \n",
    "    def add_documents(self, docs):\n",
    "        \"\"\"添加文档并计算嵌入\"\"\"\n",
    "        self.documents = docs\n",
    "        self.embeddings = self.model.encode(docs)\n",
    "    \n",
    "    def search(self, query, top_k=3):\n",
    "        \"\"\"语义搜索\"\"\"\n",
    "        query_embedding = self.model.encode([query])[0]\n",
    "        \n",
    "        # 计算余弦相似度\n",
    "        similarities = np.dot(self.embeddings, query_embedding) / (\n",
    "            np.linalg.norm(self.embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    "        )\n",
    "        \n",
    "        # 获取 top-k\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        return [(self.documents[i], similarities[i]) for i in top_indices]\n",
    "\n",
    "# 使用示例\n",
    "semantic_rag = SemanticRAG()\n",
    "\n",
    "documents = [\n",
    "    \"Python 是一种解释型、高级、通用编程语言。\",\n",
    "    \"机器学习是人工智能的一个分支。\",\n",
    "    \"神经网络是深度学习的基础。\",\n",
    "    \"自然语言处理让计算机理解人类语言。\",\n",
    "    \"计算机视觉让机器理解图像内容。\"\n",
    "]\n",
    "\n",
    "semantic_rag.add_documents(documents)\n",
    "\n",
    "# 语义搜索\n",
    "query = \"如何让电脑理解文字？\"\n",
    "results = semantic_rag.search(query)\n",
    "\n",
    "print(f\"查询: {query}\\n\")\n",
    "print(\"搜索结果:\")\n",
    "for doc, score in results:\n",
    "    print(f\"  [{score:.4f}] {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. LLM Agent 简介\n",
    "\n",
    "Agent 是能够使用工具、规划任务的 LLM 应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单的 Agent 框架\n",
    "class SimpleAgent:\n",
    "    \"\"\"简单的 Agent 实现\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_func):\n",
    "        self.llm = llm_func\n",
    "        self.tools = {}\n",
    "    \n",
    "    def register_tool(self, name, func, description):\n",
    "        \"\"\"注册工具\"\"\"\n",
    "        self.tools[name] = {\n",
    "            \"func\": func,\n",
    "            \"description\": description\n",
    "        }\n",
    "    \n",
    "    def get_tools_prompt(self):\n",
    "        \"\"\"生成工具描述\"\"\"\n",
    "        tools_desc = \"可用工具:\\n\"\n",
    "        for name, tool in self.tools.items():\n",
    "            tools_desc += f\"- {name}: {tool['description']}\\n\"\n",
    "        return tools_desc\n",
    "    \n",
    "    def parse_action(self, response):\n",
    "        \"\"\"解析 LLM 返回的动作\"\"\"\n",
    "        # 简单的解析逻辑\n",
    "        for tool_name in self.tools:\n",
    "            if f\"使用 {tool_name}\" in response or f\"调用 {tool_name}\" in response:\n",
    "                return tool_name\n",
    "        return None\n",
    "    \n",
    "    def run(self, task):\n",
    "        \"\"\"执行任务\"\"\"\n",
    "        prompt = f\"\"\"{self.get_tools_prompt()}\n",
    "任务: {task}\n",
    "\n",
    "请分析任务并决定使用哪个工具。格式: \"使用 [工具名]：[参数]\"\n",
    "如果不需要工具，直接回答。\"\"\"\n",
    "        \n",
    "        # 这里应该调用 LLM\n",
    "        # response = self.llm(prompt)\n",
    "        \n",
    "        # 模拟响应\n",
    "        print(f\"Agent 收到任务: {task}\")\n",
    "        print(f\"Prompt 预览:\\n{prompt}\")\n",
    "        \n",
    "        return \"Agent 响应将在这里返回\"\n",
    "\n",
    "# 示例工具\n",
    "def calculator(expression):\n",
    "    \"\"\"计算数学表达式\"\"\"\n",
    "    return eval(expression)\n",
    "\n",
    "def search_web(query):\n",
    "    \"\"\"搜索网络（模拟）\"\"\"\n",
    "    return f\"搜索结果：关于 '{query}' 的信息...\"\n",
    "\n",
    "# 创建 Agent\n",
    "agent = SimpleAgent(llm_func=None)\n",
    "agent.register_tool(\"calculator\", calculator, \"计算数学表达式\")\n",
    "agent.register_tool(\"search\", search_web, \"搜索网络获取信息\")\n",
    "\n",
    "# 测试\n",
    "agent.run(\"帮我计算 123 * 456 的结果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 实际应用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码生成助手\n",
    "def code_generation_prompt(task, language=\"Python\"):\n",
    "    \"\"\"生成代码任务的 Prompt\"\"\"\n",
    "    return f\"\"\"请用 {language} 完成以下编程任务：\n",
    "\n",
    "任务描述：{task}\n",
    "\n",
    "要求：\n",
    "1. 代码需要完整可运行\n",
    "2. 添加必要的注释\n",
    "3. 处理可能的异常情况\n",
    "4. 提供使用示例\n",
    "\n",
    "请生成代码：\"\"\"\n",
    "\n",
    "# 文档问答助手\n",
    "def qa_prompt(context, question):\n",
    "    \"\"\"生成问答任务的 Prompt\"\"\"\n",
    "    return f\"\"\"请根据以下文档内容回答问题。\n",
    "\n",
    "文档内容：\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "要求：\n",
    "- 只根据文档内容回答\n",
    "- 如果文档中没有相关信息，请明确说明\n",
    "- 回答要准确、简洁\n",
    "\n",
    "回答：\"\"\"\n",
    "\n",
    "# 数据分析助手\n",
    "def data_analysis_prompt(data_description, analysis_goal):\n",
    "    \"\"\"生成数据分析任务的 Prompt\"\"\"\n",
    "    return f\"\"\"请帮我分析以下数据：\n",
    "\n",
    "数据描述：\n",
    "{data_description}\n",
    "\n",
    "分析目标：\n",
    "{analysis_goal}\n",
    "\n",
    "请提供：\n",
    "1. 建议的分析方法\n",
    "2. Python 代码实现\n",
    "3. 如何解读结果\n",
    "\n",
    "分析方案：\"\"\"\n",
    "\n",
    "print(\"各种应用场景的 Prompt 模板已准备好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 练习题\n",
    "\n",
    "### 练习1：设计 Prompt\n",
    "为以下场景设计有效的 Prompt：\n",
    "- 代码 Bug 分析\n",
    "- 文本摘要\n",
    "- 翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里编写代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习2：实现 RAG 应用\n",
    "使用提供的 RAG 框架，构建一个简单的知识库问答系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里编写代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 本课小结\n",
    "\n",
    "### Prompt Engineering 要点\n",
    "\n",
    "1. **明确指令**：清楚说明任务\n",
    "2. **提供上下文**：给出背景信息\n",
    "3. **指定格式**：说明输出要求\n",
    "4. **给出示例**：Few-shot learning\n",
    "5. **引导推理**：Chain of Thought\n",
    "\n",
    "### LLM 应用模式\n",
    "\n",
    "| 模式 | 描述 | 适用场景 |\n",
    "|------|------|----------|\n",
    "| 直接提问 | 单轮对话 | 简单问答 |\n",
    "| RAG | 检索增强 | 知识库问答 |\n",
    "| Agent | 工具调用 | 复杂任务 |\n",
    "| Fine-tuning | 模型微调 | 特定领域 |\n",
    "\n",
    "### API 选择建议\n",
    "\n",
    "1. **OpenAI/Claude**：商业应用，高质量\n",
    "2. **Ollama + 开源模型**：本地部署，隐私保护\n",
    "3. **HuggingFace**：研究和实验\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "1. API 费用管理\n",
    "2. 响应延迟处理\n",
    "3. 错误重试机制\n",
    "4. 内容安全过滤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}