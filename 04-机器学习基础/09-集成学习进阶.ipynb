{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9课：集成学习进阶\n",
    "\n",
    "## 学习目标\n",
    "- 深入理解 Boosting 原理\n",
    "- 掌握 XGBoost 的使用\n",
    "- 掌握 LightGBM 的使用\n",
    "- 了解 CatBoost 的特点\n",
    "- 学习 Stacking 集成方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Boosting 回顾\n",
    "\n",
    "Boosting 是一种将弱学习器组合成强学习器的方法：\n",
    "\n",
    "- **串行训练**：每个模型都试图纠正前一个模型的错误\n",
    "- **加权投票**：最终预测是所有模型的加权组合\n",
    "- **代表算法**：AdaBoost、Gradient Boosting、XGBoost、LightGBM、CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"训练集: {X_train.shape}\")\n",
    "print(f\"测试集: {X_test.shape}\")\n",
    "print(f\"特征名: {cancer.feature_names[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sklearn Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn 的 Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "\n",
    "print(\"Sklearn Gradient Boosting:\")\n",
    "print(f\"准确率: {accuracy_score(y_test, y_pred_gb):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost\n",
    "\n",
    "XGBoost (eXtreme Gradient Boosting) 是目前最流行的 Boosting 库之一。\n",
    "\n",
    "主要特点：\n",
    "- 正则化防止过拟合\n",
    "- 并行处理加速训练\n",
    "- 支持缺失值\n",
    "- 内置交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装: pip install xgboost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(f\"XGBoost 版本: {xgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"请先安装 xgboost: pip install xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# 创建 XGBoost 分类器\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "print(\"XGBoost:\")\n",
    "print(f\"准确率: {accuracy_score(y_test, y_pred_xgb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征重要性\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': cancer.feature_names,\n",
    "    'importance': xgb_clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'][:15], feature_importance['importance'][:15])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('XGBoost Feature Importance (Top 15)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用早停 (Early Stopping)\n",
    "xgb_clf_es = xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "xgb_clf_es.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"最佳迭代次数: {xgb_clf_es.best_iteration}\")\n",
    "print(f\"准确率: {accuracy_score(y_test, xgb_clf_es.predict(X_test)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LightGBM\n",
    "\n",
    "LightGBM 是微软开发的高效 Boosting 框架。\n",
    "\n",
    "主要特点：\n",
    "- **Leaf-wise 生长**：比 Level-wise 更高效\n",
    "- **直方图算法**：加速特征分裂\n",
    "- **支持类别特征**：无需编码\n",
    "- **训练速度极快**：尤其适合大数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装: pip install lightgbm\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(f\"LightGBM 版本: {lgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"请先安装 lightgbm: pip install lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# 创建 LightGBM 分类器\n",
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_clf.predict(X_test)\n",
    "\n",
    "print(\"LightGBM:\")\n",
    "print(f\"准确率: {accuracy_score(y_test, y_pred_lgb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 两种特征重要性\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Split 重要性\n",
    "lgb.plot_importance(lgb_clf, importance_type='split', max_num_features=15, ax=axes[0])\n",
    "axes[0].set_title('Feature Importance (Split)')\n",
    "\n",
    "# Gain 重要性\n",
    "lgb.plot_importance(lgb_clf, importance_type='gain', max_num_features=15, ax=axes[1])\n",
    "axes[1].set_title('Feature Importance (Gain)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CatBoost\n",
    "\n",
    "CatBoost 是 Yandex 开发的 Boosting 框架，特别擅长处理类别特征。\n",
    "\n",
    "主要特点：\n",
    "- **有序目标编码**：处理类别特征\n",
    "- **对称树**：平衡树结构\n",
    "- **无需参数调优**：默认参数就很好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装: pip install catboost\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    import catboost\n",
    "    print(f\"CatBoost 版本: {catboost.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"请先安装 catboost: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 创建 CatBoost 分类器\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    learning_rate=0.1,\n",
    "    depth=3,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "cat_clf.fit(X_train, y_train)\n",
    "y_pred_cat = cat_clf.predict(X_test)\n",
    "\n",
    "print(\"CatBoost:\")\n",
    "print(f\"准确率: {accuracy_score(y_test, y_pred_cat):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 三大 Boosting 库对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 性能对比\n",
    "results = []\n",
    "\n",
    "# Sklearn GB\n",
    "start = time.time()\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_time = time.time() - start\n",
    "gb_acc = accuracy_score(y_test, gb_clf.predict(X_test))\n",
    "results.append({'Model': 'Sklearn GB', 'Accuracy': gb_acc, 'Time': gb_time})\n",
    "\n",
    "# XGBoost\n",
    "start = time.time()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "xgb_time = time.time() - start\n",
    "xgb_acc = accuracy_score(y_test, xgb_clf.predict(X_test))\n",
    "results.append({'Model': 'XGBoost', 'Accuracy': xgb_acc, 'Time': xgb_time})\n",
    "\n",
    "# LightGBM\n",
    "start = time.time()\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "lgb_time = time.time() - start\n",
    "lgb_acc = accuracy_score(y_test, lgb_clf.predict(X_test))\n",
    "results.append({'Model': 'LightGBM', 'Accuracy': lgb_acc, 'Time': lgb_time})\n",
    "\n",
    "# CatBoost\n",
    "start = time.time()\n",
    "cat_clf.fit(X_train, y_train, verbose=False)\n",
    "cat_time = time.time() - start\n",
    "cat_acc = accuracy_score(y_test, cat_clf.predict(X_test))\n",
    "results.append({'Model': 'CatBoost', 'Accuracy': cat_acc, 'Time': cat_time})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化对比\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 准确率\n",
    "axes[0].bar(results_df['Model'], results_df['Accuracy'], color=['blue', 'green', 'red', 'purple'])\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Model Accuracy Comparison')\n",
    "axes[0].set_ylim(0.9, 1.0)\n",
    "\n",
    "# 训练时间\n",
    "axes[1].bar(results_df['Model'], results_df['Time'], color=['blue', 'green', 'red', 'purple'])\n",
    "axes[1].set_ylabel('Time (seconds)')\n",
    "axes[1].set_title('Training Time Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. XGBoost 参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 重要参数\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n最佳参数: {xgb_grid.best_params_}\")\n",
    "print(f\"最佳分数: {xgb_grid.best_score_:.4f}\")\n",
    "print(f\"测试集准确率: {accuracy_score(y_test, xgb_grid.predict(X_test)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Stacking 集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义基础模型\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    ('xgb', xgb.XGBClassifier(n_estimators=50, random_state=42, eval_metric='logloss')),\n",
    "    ('lgb', lgb.LGBMClassifier(n_estimators=50, random_state=42, verbose=-1))\n",
    "]\n",
    "\n",
    "# 创建 Stacking 分类器\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred_stack = stacking_clf.predict(X_test)\n",
    "\n",
    "print(\"Stacking 集成:\")\n",
    "print(f\"准确率: {accuracy_score(y_test, y_pred_stack):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 回归任务示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载房价数据\n",
    "housing = fetch_california_housing()\n",
    "X_reg, y_reg = housing.data, housing.target\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"训练集: {X_train_r.shape}\")\n",
    "print(f\"目标变量范围: {y_reg.min():.2f} - {y_reg.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练回归模型\n",
    "xgb_reg = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "lgb_reg = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, verbose=-1)\n",
    "\n",
    "xgb_reg.fit(X_train_r, y_train_r)\n",
    "lgb_reg.fit(X_train_r, y_train_r)\n",
    "\n",
    "# 预测\n",
    "y_pred_xgb_r = xgb_reg.predict(X_test_r)\n",
    "y_pred_lgb_r = lgb_reg.predict(X_test_r)\n",
    "\n",
    "print(\"XGBoost 回归:\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test_r, y_pred_xgb_r)):.4f}\")\n",
    "print(f\"  R2: {r2_score(y_test_r, y_pred_xgb_r):.4f}\")\n",
    "\n",
    "print(\"\\nLightGBM 回归:\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test_r, y_pred_lgb_r)):.4f}\")\n",
    "print(f\"  R2: {r2_score(y_test_r, y_pred_lgb_r):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 练习题\n",
    "\n",
    "### 练习1：使用 LightGBM 进行调参\n",
    "对 LightGBM 进行网格搜索调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里编写代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习2：自定义 Stacking\n",
    "尝试不同的基础模型组合，比较 Stacking 效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里编写代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 本课小结\n",
    "\n",
    "### 三大 Boosting 库对比\n",
    "\n",
    "| 特性 | XGBoost | LightGBM | CatBoost |\n",
    "|------|---------|----------|----------|\n",
    "| 树生长策略 | Level-wise | Leaf-wise | Symmetric |\n",
    "| 训练速度 | 中等 | 最快 | 较慢 |\n",
    "| 内存使用 | 中等 | 最低 | 较高 |\n",
    "| 类别特征 | 需编码 | 支持 | 最佳支持 |\n",
    "| 默认效果 | 好 | 好 | 最好 |\n",
    "| GPU 支持 | 是 | 是 | 是 |\n",
    "\n",
    "### 选择建议\n",
    "\n",
    "1. **XGBoost**：通用性最强，社区支持最好\n",
    "2. **LightGBM**：大数据集首选，训练最快\n",
    "3. **CatBoost**：有类别特征时首选，开箱即用\n",
    "\n",
    "### 重要参数\n",
    "\n",
    "- **n_estimators**：树的数量\n",
    "- **learning_rate**：学习率，越小需要更多树\n",
    "- **max_depth**：树的最大深度\n",
    "- **subsample**：样本采样比例\n",
    "- **colsample_bytree**：特征采样比例"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
