{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8课：支持向量机 (SVM)\n",
    "\n",
    "## 学习目标\n",
    "- 理解支持向量机的核心思想\n",
    "- 掌握线性 SVM 和核 SVM\n",
    "- 学习 SVM 用于分类和回归\n",
    "- 了解核函数的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_moons, make_circles\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM 基本概念\n",
    "\n",
    "支持向量机 (Support Vector Machine) 是一种强大的监督学习算法，核心思想是：\n",
    "\n",
    "- **最大间隔**：找到一个超平面，使得离它最近的样本点（支持向量）到它的距离最大\n",
    "- **支持向量**：离决策边界最近的那些样本点\n",
    "- **核技巧**：通过核函数将数据映射到高维空间，解决非线性问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 线性 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成线性可分数据\n",
    "np.random.seed(42)\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_redundant=0,\n",
    "                           n_informative=2, n_clusters_per_class=1,\n",
    "                           class_sep=2.0, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape}\")\n",
    "print(f\"测试集大小: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练线性 SVM\n",
    "linear_svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "linear_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = linear_svm.predict(X_test_scaled)\n",
    "print(f\"准确率: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"\\n支持向量数量: {linear_svm.n_support_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化决策边界\n",
    "def plot_svm_decision_boundary(model, X, y, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 创建网格\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # 预测\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # 绘制\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', edgecolors='black')\n",
    "    \n",
    "    # 标记支持向量\n",
    "    plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],\n",
    "                s=200, facecolors='none', edgecolors='green', linewidths=2,\n",
    "                label='Support Vectors')\n",
    "    \n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_svm_decision_boundary(linear_svm, X_train_scaled, y_train, 'Linear SVM Decision Boundary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 核 SVM（非线性）\n",
    "\n",
    "当数据线性不可分时，使用核函数将数据映射到高维空间。\n",
    "\n",
    "常用核函数：\n",
    "- **linear**: 线性核，$K(x, y) = x^T y$\n",
    "- **poly**: 多项式核，$K(x, y) = (\\gamma x^T y + r)^d$\n",
    "- **rbf**: 高斯径向基核（默认），$K(x, y) = \\exp(-\\gamma ||x-y||^2)$\n",
    "- **sigmoid**: Sigmoid 核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成非线性数据 - 月牙形\n",
    "X_moons, y_moons = make_moons(n_samples=300, noise=0.15, random_state=42)\n",
    "\n",
    "# 生成非线性数据 - 同心圆\n",
    "X_circles, y_circles = make_circles(n_samples=300, noise=0.1, factor=0.5, random_state=42)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap='RdYlBu', edgecolors='black')\n",
    "axes[0].set_title('Moons Dataset')\n",
    "\n",
    "axes[1].scatter(X_circles[:, 0], X_circles[:, 1], c=y_circles, cmap='RdYlBu', edgecolors='black')\n",
    "axes[1].set_title('Circles Dataset')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比较不同核函数\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, kernel in enumerate(kernels):\n",
    "    # 月牙数据\n",
    "    svm_moons = SVC(kernel=kernel, gamma='auto', random_state=42)\n",
    "    svm_moons.fit(X_moons, y_moons)\n",
    "    \n",
    "    # 同心圆数据\n",
    "    svm_circles = SVC(kernel=kernel, gamma='auto', random_state=42)\n",
    "    svm_circles.fit(X_circles, y_circles)\n",
    "    \n",
    "    # 绘制月牙\n",
    "    ax = axes[0, idx]\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_moons[:, 0].min() - 0.5, X_moons[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_moons[:, 1].min() - 0.5, X_moons[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = svm_moons.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    ax.scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap='RdYlBu', edgecolors='black', s=20)\n",
    "    ax.set_title(f'Moons - {kernel}')\n",
    "    \n",
    "    # 绘制同心圆\n",
    "    ax = axes[1, idx]\n",
    "    x_min, x_max = X_circles[:, 0].min() - 0.5, X_circles[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_circles[:, 1].min() - 0.5, X_circles[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = svm_circles.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    ax.scatter(X_circles[:, 0], X_circles[:, 1], c=y_circles, cmap='RdYlBu', edgecolors='black', s=20)\n",
    "    ax.set_title(f'Circles - {kernel}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 重要参数\n",
    "\n",
    "### C 参数（正则化）\n",
    "- C 值大：更严格，允许更少的错误分类\n",
    "- C 值小：更宽松，允许更多的错误分类（更好的泛化）\n",
    "\n",
    "### gamma 参数（RBF 核）\n",
    "- gamma 值大：决策边界更复杂，容易过拟合\n",
    "- gamma 值小：决策边界更平滑，可能欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C 参数的影响\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for idx, C in enumerate(C_values):\n",
    "    svm = SVC(kernel='rbf', C=C, gamma='auto', random_state=42)\n",
    "    svm.fit(X_moons, y_moons)\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_moons[:, 0].min() - 0.5, X_moons[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_moons[:, 1].min() - 0.5, X_moons[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = svm.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    ax.scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap='RdYlBu', edgecolors='black', s=20)\n",
    "    ax.set_title(f'C = {C}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma 参数的影响\n",
    "gamma_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for idx, gamma in enumerate(gamma_values):\n",
    "    svm = SVC(kernel='rbf', C=1, gamma=gamma, random_state=42)\n",
    "    svm.fit(X_moons, y_moons)\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_moons[:, 0].min() - 0.5, X_moons[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_moons[:, 1].min() - 0.5, X_moons[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = svm.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    ax.scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap='RdYlBu', edgecolors='black', s=20)\n",
    "    ax.set_title(f'gamma = {gamma}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 网格搜索调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    X_moons, y_moons, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.01, 0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "# 网格搜索\n",
    "grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_m, y_train_m)\n",
    "\n",
    "print(f\"最佳参数: {grid_search.best_params_}\")\n",
    "print(f\"最佳交叉验证分数: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 测试集评估\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_m = best_model.predict(X_test_m)\n",
    "print(f\"测试集准确率: {accuracy_score(y_test_m, y_pred_m):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 支持向量回归 (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成回归数据\n",
    "np.random.seed(42)\n",
    "X_reg = np.sort(5 * np.random.rand(100, 1), axis=0)\n",
    "y_reg = np.sin(X_reg).ravel() + np.random.randn(100) * 0.1\n",
    "\n",
    "# 训练不同核的 SVR\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=100)\n",
    "svr_poly = SVR(kernel='poly', C=100, degree=3)\n",
    "\n",
    "svr_rbf.fit(X_reg, y_reg)\n",
    "svr_lin.fit(X_reg, y_reg)\n",
    "svr_poly.fit(X_reg, y_reg)\n",
    "\n",
    "# 预测\n",
    "X_plot = np.linspace(0, 5, 100).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.scatter(X_reg, y_reg, color='darkorange', label='Data')\n",
    "plt.plot(X_plot, svr_rbf.predict(X_plot), color='navy', label='RBF')\n",
    "plt.plot(X_plot, svr_lin.predict(X_plot), color='green', label='Linear')\n",
    "plt.plot(X_plot, svr_poly.predict(X_plot), color='red', label='Polynomial')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Support Vector Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 多分类 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载鸢尾花数据\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "# 划分数据\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, random_state=42)\n",
    "\n",
    "# 标准化\n",
    "scaler_iris = StandardScaler()\n",
    "X_train_i_scaled = scaler_iris.fit_transform(X_train_i)\n",
    "X_test_i_scaled = scaler_iris.transform(X_test_i)\n",
    "\n",
    "# 训练 SVM (默认使用 OvO 策略)\n",
    "svm_iris = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)\n",
    "svm_iris.fit(X_train_i_scaled, y_train_i)\n",
    "\n",
    "# 预测\n",
    "y_pred_i = svm_iris.predict(X_test_i_scaled)\n",
    "\n",
    "print(\"多分类 SVM 结果:\")\n",
    "print(f\"准确率: {accuracy_score(y_test_i, y_pred_i):.4f}\")\n",
    "print(f\"\\n分类报告:\\n{classification_report(y_test_i, y_pred_i, target_names=iris.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_test_i, y_pred_i)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Iris Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 练习题\n",
    "\n",
    "### 练习1：乳腺癌分类\n",
    "使用 sklearn 的乳腺癌数据集，训练一个 SVM 分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 加载数据\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer, y_cancer = cancer.data, cancer.target\n",
    "\n",
    "# 在这里编写代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习2：参数调优\n",
    "对上面的乳腺癌分类器进行网格搜索调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里编写代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 本课小结\n",
    "\n",
    "1. **核心思想**：SVM 寻找最大间隔的决策边界\n",
    "2. **支持向量**：离边界最近的样本，决定了边界位置\n",
    "3. **核函数**：将非线性问题转化为高维空间的线性问题\n",
    "4. **常用核**：linear、poly、rbf（最常用）、sigmoid\n",
    "5. **重要参数**：\n",
    "   - C：正则化强度，控制错误分类的惩罚\n",
    "   - gamma：RBF 核的带宽，影响决策边界复杂度\n",
    "6. **SVR**：支持向量机的回归版本\n",
    "7. **多分类**：默认使用 OvO (One-vs-One) 策略\n",
    "\n",
    "### SVM 的优缺点\n",
    "\n",
    "**优点**：\n",
    "- 在高维空间表现良好\n",
    "- 内存效率高（只存储支持向量）\n",
    "- 通过核函数处理非线性问题\n",
    "\n",
    "**缺点**：\n",
    "- 大数据集训练较慢\n",
    "- 对特征缩放敏感\n",
    "- 参数调优较复杂"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
